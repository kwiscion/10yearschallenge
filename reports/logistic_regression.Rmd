---
title: "Cosine similarity - baseline model"
output: html_notebook
params:
  trainset_file: data/10yearschallenge_trainset_embeddings.csv
  predictions_dir: data/predictions
  models_dir: models
---

I will use cosine similarity between vectors as a baseline model.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
source('scripts/utils.R')

trainset <- read_csv(params$trainset_file)
```

```{r}
glimpse(trainset[1:10])
```

## Create model

In this case, as cosine similarity is no *trained* model, I will create just an empty model as a placholder.

```{r}
diff <- (trainset[grepl('V1_', colnames(trainset))] - trainset[grepl('V2_', colnames(trainset))])^2
colnames(diff) <- gsub('V1', 'DIFF', colnames(diff))
log_diff <- log(diff)
colnames(log_diff) <- gsub('DIFF', 'LOG', colnames(log_diff))
trainset_glm <- bind_cols(trainset, diff, log_diff)
```

```{r fig.width=12, message=FALSE, warning=FALSE}
preds_all <- colnames(trainset_glm)[grep('DIFF|V1|V2|LOG', colnames(trainset_glm))]
preds_diffs <- colnames(trainset_glm)[grep('DIFF', colnames(trainset_glm))]
preds_logdiffs <- colnames(trainset_glm)[grep('LOG', colnames(trainset_glm))]

trainset_glm %>%
  filter(set == 'train') %>%
  modelr::crossv_kfold(10) %>%
  mutate(model_diffs = map(train, ~glm(as.formula(sprintf('match ~ %s', paste(preds_diffs, collapse = ' + '))), data=., family = 'binomial')),
         model_logdiffs = map(train, ~glm(as.formula(sprintf('match ~ %s', paste(preds_logdiffs, collapse = ' + '))), data=., family = 'binomial')),
         model_all = map(train, ~glm(as.formula(sprintf('match ~ %s', paste(preds_all, collapse = ' + '))), data=., family = 'binomial'))) %>%
  gather(model, model_fit, starts_with('model')) %>%
  mutate(predictions = map2(model_fit, 
                            test, 
                            ~data.frame(match = as.data.frame(.y)$match, 
                                        score = predict(.x, newdata = .y, type = 'response')))) %>%
  unnest(predictions) %>%
  mutate(set = 'train') %>%
  plotModelDiagnostic(match, score, model, set)

```




## Store model

### Create prediction method

```{r}
# Define prediction method ------------------------------------------------
predict_method <- function(object, data) {
  
diff_cols <- (data[grepl('V1_', colnames(data))] - data[grepl('V2_', colnames(data))])^2
colnames(diff_cols) <- gsub('V1', 'DIFF', colnames(diff_cols))
data <- bind_cols(data, tmp)

predict.glm(object, newdata = data, type = 'response')
}
```

### Store model

```{r}
model_name <- 'glm_diff_squared'

model_path <- sprintf('%s/%s.rds', params$models_dir, model_name)
storeModel(model, predict_method, model_name, model_path)
```

## Evaluate model

### Load model

```{r}
model_name <- 'glm_diff_squared'

model_path <- sprintf('%s/%s.rds', params$models_dir, model_name)
model <- loadModel(model_path)
```

### Predict

```{r}
predictions <- trainset %>%
  mutate(., score = predict(model, .)) %>%
  select(-starts_with('V')) %>%
  mutate(model = model_name)

summary(predictions)

predictios_path <- sprintf('%s/%s.csv', params$predictions_dir, model_name)
write_csv(predictions, predictios_path)
```

### Evaluate

```{r fig.width=12, message=FALSE, warning=FALSE}
plotModelDiagnostic(predictions, match, score, model, set)
```



