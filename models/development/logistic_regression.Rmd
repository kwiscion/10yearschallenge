---
title: "Logistic regression"
output: html_notebook
params:
  trainset_file: data/10yearschallenge_trainset_embeddings.csv
  predictions_dir: data/predictions
  models_dir: models
---

Simplest possible approach

```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse)
source('scripts/utils.R')

trainset <- read_csv(params$trainset_file)
```

```{r}
glimpse(trainset[1:10])
```

## Create model

In this case, as cosine similarity is no *trained* model, I will create just an empty model as a placholder.

```{r}
diff <- (trainset[grepl('V1_', colnames(trainset))] - trainset[grepl('V2_', colnames(trainset))])^2
colnames(diff) <- gsub('V1', 'DIFF', colnames(diff))
sqrt_diff <- sqrt(diff)
colnames(sqrt_diff) <- gsub('DIFF', 'SQRT', colnames(sqrt_diff))
log_diff <- log(diff)
colnames(log_diff) <- gsub('DIFF', 'LOG', colnames(log_diff))
trainset_glm <- bind_cols(trainset, diff, log_diff, sqrt_diff)
```

```{r fig.width=12, message=FALSE, warning=FALSE}
glm_custom <- function(preds, data) {
  formula <- as.formula(sprintf('match ~ %s', paste(preds, collapse = ' + ')))
  glm(formula, data=data, family = 'binomial')
}

preds_embeddings <- colnames(trainset_glm)[grep('V1|V2', colnames(trainset_glm))]
preds_diffs <- colnames(trainset_glm)[grep('DIFF', colnames(trainset_glm))]
preds_logdiffs <- colnames(trainset_glm)[grep('LOG', colnames(trainset_glm))]
preds_sqrtdiffs <- colnames(trainset_glm)[grep('SQRT', colnames(trainset_glm))]

trainset_predictions <- trainset_glm %>%
  filter(set == 'train') %>%
  modelr::crossv_kfold(10) %>%
  mutate(model_diffs = map(train, ~glm_custom(preds_diffs, data=.)),
         model_logdiffs = map(train, ~glm_custom(preds_logdiffs, data=.)),
         model_sqrtdiffs = map(train, ~glm_custom(preds_sqrtdiffs, data=.)),
         model_diffs_sqrtdiffs = map(train, ~glm_custom(c(preds_diffs, preds_sqrtdiffs), data=.)),
         model_all = map(train, ~glm_custom(c(preds_diffs, preds_sqrtdiffs, preds_logdiffs, preds_embeddings), data=.))) %>%
  gather(model, model_fit, starts_with('model')) %>%
  mutate(predictions = map2(model_fit, 
                            test, 
                            ~data.frame(match = as.data.frame(.y)$match, 
                                        score = predict(.x, newdata = .y, type = 'response')))) %>%
  unnest(predictions)
  
trainset_predictions %>%
  plotModelDiagnostic(match, score, model, rescale_scores = TRUE)

```

## Final model
```{r}
model <- glm_custom(preds_sqrtdiffs, data=trainset_glm %>% filter(set == 'train'))
```

## Store model

### Create prediction method

```{r}
# Define prediction method ------------------------------------------------
predict_method <- function(object, data) {
  
  diff <- (data[grepl('V1_', colnames(data))] - data[grepl('V2_', colnames(data))])^2
  colnames(diff) <- gsub('V1', 'DIFF', colnames(diff))
  sqrt_diff <- sqrt(diff)
  colnames(sqrt_diff) <- gsub('DIFF', 'SQRT', colnames(sqrt_diff))
  data <- bind_cols(data, diff, sqrt_diff)
  
  predict.glm(object, newdata = data, type = 'response')
}
```

### Store model

```{r}
model_name <- 'glm_diff_squared'

model_path <- sprintf('%s/%s.rds', params$models_dir, model_name)
storeModel(model, predict_method, model_name, model_path)
```

## Evaluate model

### Load model

```{r}
model_name <- 'glm_diff_squared'

model_path <- sprintf('%s/%s.rds', params$models_dir, model_name)
model <- loadModel(model_path)
```

### Predict

```{r}
predictions <- trainset %>%
  mutate(., score = predict(model, .)) %>%
  select(-starts_with('V')) %>%
  mutate(model = model_name)

summary(predictions)

predictios_path <- sprintf('%s/%s.csv', params$predictions_dir, model_name)
write_csv(predictions, predictios_path)
```

### Evaluate

```{r fig.width=12, message=FALSE, warning=FALSE}
plotModelDiagnostic(predictions, match, score, model)
```



